\subsection{Developing sudo-simulators and training process}

We use artificial neural networks to estimate a signal properties (i.e., peak ground acceleration, peak ground velocity, response spectra, and area under signal envelop) of each station based on Q model input parameters (i.e. $c,~\alpha,~and~\beta$). Artificial neural networks (ANNs) are inspired in the human brain. A given network is the combination of different so-called neurons which have certain initial weight and activation functions. One can train a network using available data by means of a process during which the weights and bias values associated with the network's neurons are updated so that these will produce output results with increasingly lower residuals in comparison with the input observations.  Training of an ANN provides the means to avoid repeated demanding computations. ANNs are extensively used in pattern recognition, classification and function regression and other aspects of science \citep[][.] {Hinton2012deep,Baughman2014neural,Graves2013speech,Dahl2012context,Toshev2014deeppose}
ANNs also used in  ground motion prediction \citep{Hong2012observations,Ghaffarzadeh2013neural,paolucci2018broad}. Although some of these previous efforts have shown good and promising results, the alternative conventional simulation methods remained as a better computational alternative. In other words, training of the network was more expensive than running the simulations. This may, however, not be the case for 3D physics-based simulations where one wants to conduct an optimization processes that needs to run the simulation thousands of time.\\
Studying neural network structure and different networks and algorithm are beyond the scope of this study.  In this study we use as simple structure of neural network with 3 input values and 1-8 output values with three hidden layers. We use Feed-Forward Neural Network and Levenberg-Marquardt optimization as a network training function in order to update weight and bias values. We use linear transfer function for the last layers and hyperbolic tangent-sigmoid transfer function for the rest of them. The package is implemented in Matlab programming tool. More network details will be provided in results section. The algorithm divides the data into three sets including: training, validation, and test dataset. Validation dataset is used to stop training process to avoid overfitting during the training process. The test dataset is used after fully training data to analyze the functionality of network. Neural networks' training process, depending on the size of network, are involved with hundreds of thousands of matrix multiplication. Therefore, normalized input values ensure the stability of the network and increase its functionality. We linearly scale the data into $[-1,1]$ using

\begin{equation}
X_{norm} = \frac{2*(X-X_{min})}{(X_{max}-X_{min})}-1
\end{equation}

In general, with increasing training data, the network functionality increases for unseen data and becomes more generalizable. However, in many cases, developing training data can cost considerable amount of computational and/or financial resources. In this study we generate enough training data and study the effect of training data size in network performance. In oder to increase the network accuracy and reduce overfitting we use ensembling method through bagging approach. Going through these process the prediction model predicts the peak values with very high accuracy. 
